{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ![DeepLearning-with-Pytorch](https://puchan-hci.github.io/myweb/DeepLearning-with-Pytorch/img/01_1.jpg)Deep Learning with PyTorch\n"
      ],
      "metadata": {
        "id": "BBzK7u7xgMcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# It starts with a tensor\n",
        " The process begins by converting our input into floating-point numbers.  Since floating-point numbers are the way a network deals with information, we need a\n",
        "way to encode real-world data of the kind we want to process into something digestible\n",
        "by a network and then decode the output back to something we can understand and\n",
        "use for our purpose.\n",
        "![Floating point](https://puchan-hci.github.io/myweb/DeepLearning-with-Pytorch/img/01_2.jpg)\n",
        "\n",
        "In the context of deep learning, tensors refer to the generalization of vectors and matrices to an arbitrary number of dimensions. Another name for the same concept is multidimensional array. The dimensionality of a tensor coincides with the\n",
        "number of indexes used to refer to scalar values within the tensor.\n",
        "![Tensors](https://puchan-hci.github.io/myweb/DeepLearning-with-Pytorch/img/01_3.jpg)"
      ],
      "metadata": {
        "id": "EobQrv9-hIIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing our first tensors\n",
        "Let’s construct our first PyTorch tensor and see what it looks like."
      ],
      "metadata": {
        "id": "8UQKrB0Ajb-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfG3RM0Ic7vZ",
        "outputId": "0093d5bc-0545-4fe6-895e-9dcf7da031ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n",
            "tensor(1.)\n",
            "1.0\n",
            "tensor([1., 1., 2.])\n",
            "2.0\n"
          ]
        }
      ],
      "source": [
        "import torch                # Imports the torch module\n",
        "a = torch.ones(3)       # Creates a one-dimensional tensor of size 3 filled with 1s\n",
        "\n",
        "# After importing the torch module, we call a function that creates a (one-dimensional)\n",
        "# tensor of size 3 filled with the value 1.0. We can access an element using its zero-based\n",
        "# index or assign a new value to it.\n",
        "\n",
        "print(a)\n",
        "print(a[1])\n",
        "print(float(a[1]))\n",
        "\n",
        "# Assign a new value\n",
        "a[2] = 2.0\n",
        "print(a)\n",
        "print(float(a[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python lists or tuples of numbers are collections of Python objects that are individually allocated in memory.\n",
        "\n",
        "![Tensors](https://puchan-hci.github.io/myweb/DeepLearning-with-Pytorch/img/01_4.jpg)"
      ],
      "metadata": {
        "id": "lcrcqzfNl4vF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4Sdvk1Fc7va",
        "outputId": "f8d778b0-227b-43b4-a361-dba8559ec599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4., 1., 5., 3., 2., 1.])\n",
            "4.0 1.0\n",
            "tensor([[4., 1.],\n",
            "        [5., 3.],\n",
            "        [2., 1.]])\n",
            "torch.Size([3, 2])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[4., 1.],\n",
            "        [5., 3.],\n",
            "        [2., 1.]])\n",
            "tensor(4.)\n",
            "tensor(1.)\n",
            "tensor(5.)\n",
            "tensor(3.)\n",
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor([4., 1.])\n"
          ]
        }
      ],
      "source": [
        "points = torch.zeros(6)   # Using .zeros is just a way to get an appropriately sized array.\n",
        "points[0] = 4.0                    # We overwrite those zeros with the values we actually want.\n",
        "points[1] = 1.0\n",
        "points[2] = 5.0\n",
        "points[3] = 3.0\n",
        "points[4] = 2.0\n",
        "points[5] = 1.0\n",
        "\n",
        "# We can also pass a Python list to the constructor, to the same effect:\n",
        "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
        "print(points)\n",
        "\n",
        "# To get the coordinates of the first point, we do the following:\n",
        "print(float(points[0]), float(points[1]))\n",
        "\n",
        "# It would be practical to have the first index refer to individual 2D points\n",
        "# rather than point coordinates. For this, we can use a 2D tensor:\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "print(points)\n",
        "\n",
        "# Here, we pass a list of lists to the constructor. We can ask the tensor about its shape:\n",
        "print(points.shape)\n",
        "\n",
        "# This informs us about the size of the tensor along each dimension.\n",
        "# We could also use zeros or ones to initialize the tensor, providing the size as a tuple:\n",
        "points = torch.zeros(3, 2)\n",
        "print(points)\n",
        "\n",
        "# Now we can access an individual element in the tensor using two indices:\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "print(points)\n",
        "print(points[0, 0])\n",
        "print(points[0, 1])\n",
        "print(points[1, 0])\n",
        "print(points[1, 1])\n",
        "print(points[2, 0])\n",
        "print(points[2, 1])\n",
        "\n",
        "# We can also access the first element in the tensor to get the 2D coordinates\n",
        "# of the first point:\n",
        "print(points[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing a tensor’s dtype attribute\n",
        "In order to allocate a tensor of the right numeric type, we can specify the proper\n",
        "dtype as an argument to the constructor. For example:"
      ],
      "metadata": {
        "id": "N5hCSWc3suIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxtqy7U1c7vj",
        "outputId": "7eba86de-7261-485f-fcae-be4f0a2fa671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int16\n",
            "torch.float64\n",
            "torch.int16\n",
            "torch.float64\n",
            "torch.int16\n",
            "torch.float64\n",
            "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "double_points = torch.ones(10, 2, dtype=torch.double)\n",
        "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
        "\n",
        "# We can find out about the dtype for a tensor by accessing the corresponding attribute:\n",
        "print(short_points.dtype)\n",
        "print(double_points.dtype)\n",
        "\n",
        "# We can also cast the output of a tensor creation function to the right type\n",
        "# using the corresponding casting method, such as\n",
        "double_points = torch.zeros(10, 2).double()\n",
        "short_points = torch.ones(10, 2).short()\n",
        "print(short_points.dtype)\n",
        "print(double_points.dtype)\n",
        "\n",
        "# or the more convenient to method:\n",
        "double_points = torch.zeros(10, 2).to(torch.double)\n",
        "short_points = torch.ones(10, 2).to(dtype=torch.short)\n",
        "print(short_points.dtype)\n",
        "print(double_points.dtype)\n",
        "\n",
        "# When mixing input types in operations, the inputs are converted to the larger type\n",
        "# automatically. Thus, if we want 32-bit computation, we need to make sure all our\n",
        "# inputs are (at most) 32-bit:\n",
        "points_64 = torch.rand(5, dtype=torch.double)  # rand initializes the tensor elements to random numbers between 0 and 1.\n",
        "points_short = points_64.to(torch.short)\n",
        "print(points_64 * points_short)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors: Scenic views of storage\n",
        "Values in tensors are allocated in contiguous chunks of memory managed by *torch.Storage* instances.\n",
        "\n",
        "![Tensors](https://puchan-hci.github.io/myweb/DeepLearning-with-Pytorch/img/01_5.jpg)"
      ],
      "metadata": {
        "id": "uaxdzP8fuq1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_GAVZkSc7vj",
        "outputId": "3d3f7a99-6327-4ad6-e8bb-3b775de037ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 4.0\n",
            " 1.0\n",
            " 5.0\n",
            " 3.0\n",
            " 2.0\n",
            " 1.0\n",
            "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
            "4.0\n",
            "1.0\n",
            "5.0\n",
            "tensor([[2., 1.],\n",
            "        [5., 3.],\n",
            "        [2., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Reset points back to original value\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "print(points.storage())\n",
        "\n",
        "# We can also index into a storage manually. For instance:\n",
        "points_storage = points.storage()\n",
        "print(points_storage[0])\n",
        "print(points_storage[1])\n",
        "print(points_storage[2])\n",
        "\n",
        "# We can’t index a storage of a 2D tensor using two indices. The layout of\n",
        "# a storage is always one-dimensional, regardless of the dimensionality of\n",
        "# any and all tensors that might refer to it. At this point, it shouldn’t come as\n",
        "#  a surprise that changing the value of a storage leads to changing the content of\n",
        "#  its referring tensor:\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "points_storage = points.storage()\n",
        "points_storage[0] = 2.0\n",
        "print(points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying stored values\n",
        "In-place operations\n",
        "In addition to the operations on tensors introduced in the previous section, a small\n",
        "number of operations exist only as methods of the Tensor object. They are recognizable from a trailing underscore in their name, like zero_, which indicates that the\n",
        "method operates in place by modifying the input instead of creating a new output tensor and returning it. For instance, the zero_ method zeros out all the elements of the input."
      ],
      "metadata": {
        "id": "D0NVYdPjxa0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(3, 2)\n",
        "print(a)\n",
        "a.zero_()\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWkNr0wMx9Py",
        "outputId": "1c512968-df0e-493f-f111-3000e301d59a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy interoperability\n",
        "PyTorch tensors can\n",
        "be converted to NumPy arrays and vice versa very efficiently. By doing so, we can take\n",
        "advantage of the huge swath of functionality in the wider Python ecosystem that has\n",
        "built up around the NumPy array type."
      ],
      "metadata": {
        "id": "67c74aN00Pnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ngm7u-c7vj",
        "outputId": "e403171d-6685-48ff-c16d-d3cb4f4f6f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Get a NumPy array out of tensor\n",
        "points = torch.ones(3, 4)\n",
        "points_np = points.numpy()\n",
        "print(points_np)\n",
        "\n",
        "# Obtain a PyTorch tensor from a NumPy array\n",
        "points = torch.from_numpy(points_np)\n",
        "print(points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serializing tensors\n",
        "Creating a tensor on the fly is all well and good, but if the data inside is valuable, we will\n",
        "want to save it to a file and load it back at some point."
      ],
      "metadata": {
        "id": "u0xJ_9zL0_WR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6e8WJOdc7vj",
        "outputId": "e97033f0-dca8-4049-bbf8-49b0978ea313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "points = torch.from_numpy(points_np)\n",
        "torch.save(points, 'ourpoints.t')\n",
        "\n",
        "# We can pass a file descriptor in lieu of the filename\n",
        "with open('ourpoints_alternative.t','wb') as f:\n",
        "  torch.save(points, f)\n",
        "\n",
        "# Loading our points back is similarly a one-liner\n",
        "points = torch.load('ourpoints.t')\n",
        "\n",
        "# or, equivalently\n",
        "with open('ourpoints.t','rb') as f:\n",
        "  points = torch.load(f)\n",
        "print(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serializing to HDF5 with h5py\n",
        "HDF5 is a portable, widely supported\n",
        "format for representing serialized multidimensional arrays, organized in a nested key-value dictionary. Python supports HDF5 through the h5py library (www.h5py.org),\n",
        "which accepts and returns data in the form of NumPy arrays.\n",
        "\n",
        "We can install h5py using\n",
        "\n",
        "\n",
        "```\n",
        "$ conda install h5py\n",
        "```"
      ],
      "metadata": {
        "id": "UJRPapFj5tOm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zUMSgLO1c7vk"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "# At this point, we can save our points tensor by converting it to a NumPy array\n",
        "#  and passing it to the create_dataset function:\n",
        "f = h5py.File('ourpoints.hdf5', 'w')\n",
        "dset = f.create_dataset('coords', data=points.numpy())\n",
        "f.close()\n",
        "\n",
        "# Here 'coords' is a key into the HDF5 file. We can have other keys—even nested ones.\n",
        "# One of the interesting things in HDF5 is that we can index the dataset while on disk\n",
        "# and access only the elements we’re interested in. Let’s suppose we want to load just\n",
        "# the last two points in our dataset:\n",
        "f = h5py.File('ourpoints.hdf5', 'r')\n",
        "dset = f['coords']\n",
        "last_points = dset[-2:]\n",
        "\n",
        "# We can pass the returned object to the torch.from_numpy function to obtain\n",
        "# a tensor directly. Note that in this case, the data is copied over to the tensor’s storage:\n",
        "last_points = torch.from_numpy(dset[-2:])\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving tensors to the GPU\n",
        "Every PyTorch tensor can be transferred to (one of) the\n",
        "GPU(s) in order to perform massively parallel, fast computations. All operations that\n",
        "will be performed on the tensor will be carried out using GPU-specific routines that\n",
        "come with PyTorch."
      ],
      "metadata": {
        "id": "-xI4sHge2yaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW0jn8sNc7vk",
        "outputId": "24c1d6a2-735f-45df-add1-fcc3f6753507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 8.,  2.],\n",
            "        [10.,  6.],\n",
            "        [ 4.,  2.]])\n",
            "tensor([[16.,  4.],\n",
            "        [20., 12.],\n",
            "        [ 8.,  4.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#  we can create a tensor on the GPU by specifying the corresponding argument to\n",
        "#  the constructor:\n",
        "import torch\n",
        "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
        "\n",
        "# We could instead copy a tensor created on the CPU onto the GPU using\n",
        "# the to method:\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "points_gpu = points.to(device='cuda')\n",
        "points_gpu = points.to(device='cuda:0') # Assigning a GPU to allocate the tensor\n",
        "\n",
        "# Any operation performed on the tensor, such as multiplying all elements by a constant,\n",
        "# is carried out on the GPU\n",
        "points = 2 * points                                                   # Multiplication performed on the CPU\n",
        "print(points)\n",
        "points_gpu = 2 * points.to(device='cuda')   # Multiplication performed on the GPU\n",
        "print(points_gpu)\n",
        "\n",
        "# We can also use the shorthand methods cpu and cuda instead of the to method\n",
        "#  to achieve the same goal:\n",
        "points_gpu = points.cuda()              # Defaults to GPU index 0\n",
        "points_gpu = points.cuda(0)\n",
        "points_cpu = points_gpu.cpu()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}